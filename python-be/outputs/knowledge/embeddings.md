# Embeddings Data (embeddings.json)

The `embeddings.json` file located in `python-be/outputs/knowledge/` stores the vectorized representations (embeddings) of the textual content from the Markdown documents in the knowledge base. These embeddings are crucial for enabling semantic search and retrieval functionalities within the AI video automation pipeline.

## Purpose

-   **Semantic Search**: Allows the AI system to find relevant knowledge chunks based on the meaning of a query, rather than just keyword matching.
-   **Knowledge Retrieval**: Facilitates the retrieval of contextual information that can inform AI models during plan generation or validation.
-   **Efficiency**: Pre-computed embeddings allow for fast similarity comparisons at runtime, avoiding the need to re-vectorize text for every query.

## Structure

The `embeddings.json` file is a JSON array, where each element in the array represents a `VectorisedChunk` (as defined in `python-be/knowledge_base/models.py`). Each `VectorisedChunk` object typically contains:

-   **`doc_id`**: The identifier of the source Markdown document (e.g., `planning_guidelines.md`).
-   **`chunk_id`**: A unique identifier for the specific text chunk within its document (e.g., `planning_guidelines.md::section_0`).
-   **`text`**: The original textual content of the chunk that was vectorized.
-   **`metadata`**: A dictionary containing additional contextual information about the chunk, such as:
    -   `title`: The title of the source document.
    -   `heading`: The heading under which this chunk falls (if applicable).
    -   `path`: The file path of the source document.
-   **`vector`**: A list of floating-point numbers representing the dense vector embedding of the `text` content.

## Generation

This file is generated by the `KnowledgeBaseIngestor` (specifically the `vectorise` method) as part of the `sync_knowledge_base` process. The `Vectoriser` component (from `python-be/knowledge_base/vector_store.py`) is responsible for converting text into these numerical vectors, typically using a pre-trained SentenceTransformer model.

## Usage

The `InMemoryVectorStore` (from `python-be/knowledge_base/vector_store.py`) loads this data to build an in-memory index, which is then used by the `KnowledgeRepository` to perform semantic searches.