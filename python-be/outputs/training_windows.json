[
  {
    "index": 1,
    "start": 0.0,
    "end": 10.4,
    "duration": 10.4,
    "text": "here's a teaser what if I told you that cures for chronic disease were hidden in",
    "guideline_snippets": [
      "Recurring Cues: `highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 80,
      "sentence_count": 0,
      "word_count": 16,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.54
    }
  },
  {
    "index": 2,
    "start": 10.4,
    "end": 17.28,
    "duration": 6.880000000000001,
    "text": "our own immune systems only we could read that information out so let's take",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.03
    }
  },
  {
    "index": 3,
    "start": 17.28,
    "end": 22.84,
    "duration": 5.559999999999999,
    "text": "multiple sclerosis for example multiple sclerosis is a debilitating auto",
    "guideline_snippets": [
      "Usage: **Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns.",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Purpose: The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 72,
      "sentence_count": 0,
      "word_count": 10,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.8
    }
  },
  {
    "index": 4,
    "start": 22.84,
    "end": 28.8,
    "duration": 5.960000000000001,
    "text": "immune disease where our own cells attack the brain and for years we didn't",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "`icon`: **Purpose** - S\u1eed d\u1ee5ng c\u00e1c bi\u1ec3u t\u01b0\u1ee3ng \u0111\u1ed3 h\u1ecda t\u0129nh ho\u1eb7c c\u00f3 chuy\u1ec3n \u0111\u1ed9ng t\u1ed1i thi\u1ec3u \u0111\u1ec3 minh h\u1ecda \u00fd t\u01b0\u1edfng, cung c\u1ea5p th\u00f4ng tin nhanh ch\u00f3ng ho\u1eb7c t\u0103ng c\u01b0\u1eddng nh\u1eadn di\u1ec7n th\u01b0\u01a1ng hi\u1ec7u.\n**Layer** - `overlay` (l\u1edbp ph\u1ee7).\n**Key fields** - `content` (n\u1ed9i dung bi\u1ec3u t\u01b0\u1ee3ng, th\u01b0\u1eddng l\u00e0 t\u00ean file ho\u1eb7c ID), `context` (ng\u1eef c\u1ea3nh s\u1eed d\u1ee5ng)."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 75,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": true
    },
    "audio_features": {
      "speaking_rate_wps": 2.35
    }
  },
  {
    "index": 5,
    "start": 28.8,
    "end": 35.52,
    "duration": 6.720000000000002,
    "text": "know what caused it which makes it very difficult to treat so in January 2022 a",
    "guideline_snippets": [
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "7. Deployment Checklist: Package preprocessing scripts, model weights, `element_schema.json`, and inference pipeline.\nProvide fallbacks when confidence is low (for example, default overlays or prompts for manual review).\nLog predictions with timestamps and context for downstream auditing."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 79,
      "sentence_count": 0,
      "word_count": 16,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.38
    }
  },
  {
    "index": 6,
    "start": 35.52,
    "end": 42.24,
    "duration": 6.719999999999999,
    "text": "study came out where they followed 10 million people for 20 years and they",
    "guideline_snippets": [
      "Recurring Cues: Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 74,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.08
    }
  },
  {
    "index": 7,
    "start": 42.24,
    "end": 47.72,
    "duration": 5.479999999999997,
    "text": "found that Epstein bar virus so mono the kissing disease increased the risk of",
    "guideline_snippets": [
      "Layer & Timing Hygiene: Do not overlap full-screen overlays at the same timestamp; offset by at least 0.3 s or merge copy. *Rationale:* Respects the stack hierarchy defined in [element_definitions.md](element_definitions.md#layer-stack).\nWhen the `video` layer is active (b-roll), overlays may occupy full width; otherwise keep margins to protect speaker visibility. *Rationale:* Preserves essential facial expressions.\nEnd SFX before the next major beat and cap overlay visibility at 6-8 s unless the segment is static. *Rationale:* Aligns with [quality_criteria.md](quality_criteria.md#timing) to prevent lingering elements.",
      "Recurring Cues: Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery.",
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 78,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.55
    }
  },
  {
    "index": 8,
    "start": 47.72,
    "end": 53.84,
    "duration": 6.1200000000000045,
    "text": "multiple sclerosis by 32 times it's a big deal you might have seen it in the",
    "guideline_snippets": [
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "Motion & Transitions: Trigger `zoom_in` on turning points or emphasised statements (\"this is the key\", \"here's the mistake\"). *Rationale:* Heightens focus; validated by examples in [examples/patterns.json](examples/patterns.json).\nDeploy `zoom_out` to release tension or provide wider context after a focal point. *Rationale:* Restores viewer orientation.\nSpace identical effects by at least 0.5 s unless narrative urgency demands otherwise. *Rationale:* Enforced by `motion_rules.json`; avoids viewer fatigue (see negative cases in `patterns.json`)."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 16,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.61
    }
  },
  {
    "index": 9,
    "start": 54.36,
    "end": 59.36,
    "duration": 5.0,
    "text": "news so three days later another study came out in nature showing not just a",
    "guideline_snippets": [
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 3.0
    }
  },
  {
    "index": 10,
    "start": 59.36,
    "end": 65.72,
    "duration": 6.359999999999999,
    "text": "correlation but a direct link between Epstein bar virus and multiple sclerosis",
    "guideline_snippets": [
      "Channel Definitions: **Pattern**: Split-column text overlay for comparing different channels.\n**Elements**: `text_overlay` (overlay layer) with `split_column` style, presenting two or more channels side-by-side.\n**Rationale**: Facilitates direct comparison and highlights distinctions between various digital marketing channels.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "Recurring Cues: Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 78,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.89
    }
  },
  {
    "index": 11,
    "start": 65.72,
    "end": 75.8,
    "duration": 10.079999999999998,
    "text": "using just 12 people and sampling like once so 10 million people 20 years 12",
    "guideline_snippets": [
      "5. Training Routine: Split data by video to avoid leakage (train on one video, validate on another, rotate as more data arrives).\nUse curriculum: start with type/layer predictions, then add auxiliary heads (content, style).\nApply class balancing (oversampling rare elements like `achievement_highlight`).\nMonitor convergence per head; early-stop if accuracy plateaus but loss diverges.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "9. Risk Controls: Mitigate noisy timestamps by smoothing predictions and enforcing minimum separation thresholds defined in `motion_rules.json`.\nPrevent style drift by constraining `style` predictions to allowed set per brand guide.\nDocument assumptions about transcript accuracy; include fallbacks when speech deviates from script."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.49
    }
  },
  {
    "index": 12,
    "start": 75.8,
    "end": 84.92,
    "duration": 9.120000000000005,
    "text": "people in like a day how did they do that so the team Robinson and Lance used",
    "guideline_snippets": [
      "Usage Guidelines: **Match by Context Tags** - ensure each generated element includes `context` (see `element_schema.json`). Use it to query `context_rules.json` and retrieve permitted `broll` or `sfx` tags.\n**Validate Asset Availability** - before finalising a plan, confirm `description` or `sound` values map to existing `id`s in the relevant catalog; log fallback suggestions when no exact match is found.\n**Respect Motion Constraints** - defer to `motion_rules.json` for allowable sequences (for example, minimum 0.5 s spacing between identical zooms).\n**Enrich Training Examples** - augment training data with catalog metadata (for example, embed `mood` vectors) so the model learns to pick assets aligned with emotional tone.\n**Keep Catalogs Synced** - update version numbers and regeneration timestamps when assets change; propagate updates to downstream caches.",
      "Career Path Discussion: **Pattern**: B-roll footage illustrating career growth or industry trends.\n**Elements**: `broll` (video layer) with `description` matching the spoken content (e.g., \"modern office\", \"digital network\").\n**Rationale**: Breaks up speaker footage, adds visual interest, and metaphorically supports the narrative.",
      "Structure: The `patterns.json` file is an array of objects, where each object represents a specific editing pattern. Each pattern typically includes:\n**`name`**: A descriptive name for the pattern.\n**`description`**: A brief explanation of the pattern's intent and usage.\n**`elements`**: An array of video elements, each conforming to the `element_schema.json`, demonstrating the pattern. These elements include `timestamp`, `type`, `layer`, and other relevant properties.\n**`notes`**: Additional qualitative notes or rationale for the pattern."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 77,
      "sentence_count": 0,
      "word_count": 17,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.86
    }
  },
  {
    "index": 13,
    "start": 84.92,
    "end": 90.32,
    "duration": 5.3999999999999915,
    "text": "a snapshot of information stored in our memory immune cells to infer",
    "guideline_snippets": [
      "Extraction Reminders: Keep transcript timestamps in `M:SS` and convert to seconds during preprocessing.\nPreserve `context`, `style`, `animation`, and `sound` attributes; they contain supervision signals even when absent from transcripts.\nWhen augmenting data, cross-link transcript spans to timeline entries via timestamp proximity (+/- 1 second window works for both videos).\nTrack narrative sections (e.g., `Part 1`, `B2B vs B2C`) to help the model learn context-aware element placement.\nSynchronise with asset catalogs so generated descriptions map to real `id`s and comply with motion spacing rules.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 68,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.22
    }
  },
  {
    "index": 14,
    "start": 90.32,
    "end": 95.12,
    "duration": 4.800000000000011,
    "text": "backwards what had come before and triggered the disease or what I like to",
    "guideline_snippets": [
      "2025-10-21: Added `element_schema.json` to formalise element structure, allowed values, and validation rules.\nExpanded `examples/` with qualitative (`patterns.md`) and structured (`patterns.json`) cases, including edge and negative scenarios.\nIntroduced `asset_catalogs.md` and documented catalog usage in `data_sources.md`.\nRefined `planning_guidelines.md` with cross-references, rationales, and motion spacing rules.\nUpgraded video outlines to narrative blueprints with summaries, audiences, and emotional tone guidance.\nExpanded `glossary.md` to cover modelling terminology (Sentence-BERT, MAE, F1, etc.).\nUpdated `README.md` with new directory map and versioning instructions.",
      "Synchronisation Notes: Multiple elements can share the same timestamp; treat them as simultaneous but respect layer ordering.\nTransitions (`effect`) should begin before or exactly with the visual/text they introduce.\nUse `style` values to keep branding consistent (default: `highlighted_background` for critical callouts).\nPopulate `context` to support catalog lookups (see [asset_catalogs.md](asset_catalogs.md)).\nRecord `confidence` when available to support downstream thresholding (optional field in `element_schema.json`).",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 74,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.92
    }
  },
  {
    "index": 15,
    "start": 95.12,
    "end": 101.92,
    "duration": 6.799999999999997,
    "text": "call forensic immunology and in Robinson's case right they already knew",
    "guideline_snippets": [
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Integration Touchpoints: **Feature Engineering** - include catalog tags as additional inputs when predicting `description` or `sound`.\n**Inference** - post-process model outputs by selecting the closest matching `id` using cosine similarity between description embeddings and catalog tags.\n**Evaluation** - add assertions in `quality_criteria.md` to confirm selected assets exist and comply with `motion_rules.json`.\nRefer back to `knowledge-base/data_sources.md` for provenance and to `planning_guidelines.md` for contextual placement rules."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 71,
      "sentence_count": 0,
      "word_count": 11,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.62
    }
  },
  {
    "index": 16,
    "start": 101.92,
    "end": 107.48,
    "duration": 5.560000000000002,
    "text": "what they were looking for Epstein bar virus myelin so they only had to decode",
    "guideline_snippets": [
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract.",
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 78,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.7
    }
  },
  {
    "index": 17,
    "start": 107.48,
    "end": 115.36,
    "duration": 7.8799999999999955,
    "text": "a tiny part of the massive distributed ever evolving archive that is the memory",
    "guideline_snippets": [
      "Extraction Reminders: Keep transcript timestamps in `M:SS` and convert to seconds during preprocessing.\nPreserve `context`, `style`, `animation`, and `sound` attributes; they contain supervision signals even when absent from transcripts.\nWhen augmenting data, cross-link transcript spans to timeline entries via timestamp proximity (+/- 1 second window works for both videos).\nTrack narrative sections (e.g., `Part 1`, `B2B vs B2C`) to help the model learn context-aware element placement.\nSynchronise with asset catalogs so generated descriptions map to real `id`s and comply with motion spacing rules.",
      "2025-10-21: Added `element_schema.json` to formalise element structure, allowed values, and validation rules.\nExpanded `examples/` with qualitative (`patterns.md`) and structured (`patterns.json`) cases, including edge and negative scenarios.\nIntroduced `asset_catalogs.md` and documented catalog usage in `data_sources.md`.\nRefined `planning_guidelines.md` with cross-references, rationales, and motion spacing rules.\nUpgraded video outlines to narrative blueprints with summaries, audiences, and emotional tone guidance.\nExpanded `glossary.md` to cover modelling terminology (Sentence-BERT, MAE, F1, etc.).\nUpdated `README.md` with new directory map and versioning instructions.",
      "Three-Part Learning Framework: **Pattern**: Progressive list reveal for a multi-stage framework.\n**Elements**: Series of `text_overlay` elements with `fade_in_list` animation, each adding a new point to the previous one.\n**Rationale**: Visually reinforces the structured learning path, making it easy for viewers to follow."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 79,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.78
    }
  },
  {
    "index": 18,
    "start": 115.36,
    "end": 120.04,
    "duration": 4.680000000000007,
    "text": "immune system so the immune system stores an imprint of everything it",
    "guideline_snippets": [
      "Purpose: The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`.",
      "Feature vs. Benefit: **Pattern**: Icon effect with a subtle sound cue for emphasis.\n**Elements**: `icon` (overlay layer) appearing with a `ui_pop` `sound_effect` (audio layer) when a feature or benefit is introduced.\n**Rationale**: Draws attention to the distinction and reinforces the learning point with an auditory cue.",
      "Structure: The `patterns.json` file is an array of objects, where each object represents a specific editing pattern. Each pattern typically includes:\n**`name`**: A descriptive name for the pattern.\n**`description`**: A brief explanation of the pattern's intent and usage.\n**`elements`**: An array of video elements, each conforming to the `element_schema.json`, demonstrating the pattern. These elements include `timestamp`, `type`, `layer`, and other relevant properties.\n**`notes`**: Additional qualitative notes or rationale for the pattern."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 69,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.56
    }
  },
  {
    "index": 19,
    "start": 120.04,
    "end": 128.64,
    "duration": 8.59999999999998,
    "text": "encounters infections allergies auto immunity toxins cancer it's basically a",
    "guideline_snippets": [
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract.",
      "Channel Definitions: **Pattern**: Split-column text overlay for comparing different channels.\n**Elements**: `text_overlay` (overlay layer) with `split_column` style, presenting two or more channels side-by-side.\n**Rationale**: Facilitates direct comparison and highlights distinctions between various digital marketing channels.",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 10,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.16
    }
  },
  {
    "index": 20,
    "start": 128.72,
    "end": 134.96,
    "duration": 6.240000000000009,
    "text": "web browser history it's also how vaccines work so though we may not know",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "3. Feature Engineering: Transcript features: semantic vectors, sentence length, relative position within the video, keyword flags (for example, \"Part 1\", \"mistake\", \"option\").\nAudio/tempo proxies: estimate speaking rate via word counts per window.\nTimeline context: distance to previous/next elements, element type history, context tags (aligned to `context_rules.json`).\nStyle cues: reuse `context` labels to signal metaphors, comparisons, or emphasis needs.\nAsset compatibility: embed catalog metadata (for example, `tags`, `mood`, `intensity`) from `broll_catalog.json` and `sfx_catalog.json` for recommendation scoring.",
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 73,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.24
    }
  },
  {
    "index": 21,
    "start": 134.96,
    "end": 141.24,
    "duration": 6.280000000000001,
    "text": "what is causing a disease the immune system probably does and if we could",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Usage: **Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns.",
      "Purpose: The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 73,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.23
    }
  },
  {
    "index": 22,
    "start": 141.24,
    "end": 147.04,
    "duration": 5.799999999999983,
    "text": "decode the immune archive at scale we could apply forensic immunology to",
    "guideline_snippets": [
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps.",
      "2. Preprocess & Align: Merge transcript text with timeline entries by timestamp, producing windows (5-10 seconds) that give sufficient context.\nNormalize timestamps to seconds for easier maths and modelling.\nSegment transcripts into sentences or clauses; tokenise and build embeddings (Sentence-BERT or equivalent).\nEncode video elements: one-hot for categorical fields, embeddings for text-heavy attributes (`description`, `content`); ensure categorical vocab matches [element_schema.json](element_schema.json)."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 72,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.07
    }
  },
  {
    "index": 23,
    "start": 147.04,
    "end": 152.32,
    "duration": 5.280000000000001,
    "text": "diseases where we don't yet know the cause so that is exactly what my team",
    "guideline_snippets": [
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 74,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.84
    }
  },
  {
    "index": 24,
    "start": 152.6,
    "end": 158.68,
    "duration": 6.0800000000000125,
    "text": "aims to do and so I am thrilled to announce publicly for the first time",
    "guideline_snippets": [
      "Video 2 Narrative Blueprint: This document provides a detailed narrative blueprint for \"Video 2: Digital Marketing 101 (A Beginner's Guide to Marketing)\". It outlines the video's core elements, including its title, summary, target audience, tone, pacing, and primary themes. This blueprint serves as a guide for AI model training and video plan generation, ensuring that the output aligns with the original video's intent and structure.\n**Title:** *Digital Marketing 101 (A Beginner's Guide to Marketing)*\n**Summary:** Breaks down foundational marketing concepts, contrasting strategies, channels, and audience types to equip beginners with a holistic view.\n**Target audience:** New or transitioning marketers seeking clarity on terminology, strategy-versus-tactics differentiation, and channel selection.\n**Tone and pacing:** Energetic and instructive; balances conceptual explanation with actionable tips.\n**Primary themes:** Fundamentals first, strategy vs tactics, channel comparisons, intent-driven marketing, audience segmentation.\nSection\nTimestamp\nNarrative focus\nElement opportunities\nEmotional tone\nIntroduction\n0:00-0:30\nSets promise: become a better digital marketer.\nTitle overlay \"Digital Marketing 101\", subtitle overlay with `highlighted_background`, upbeat intro sting.\nMotivational\nDigital vs Traditional\n0:37-1:40\nDefines digital marketing and contrasts with traditional media.\nComparison overlays, `whoosh_standard` SFX, split b-roll (online vs offline).\nExplanatory\nChannel Examples\n1:02-3:10\nLists core channels: SEO, social media, PPC, email, web optimisation.\nTerm overlays with `ui_pop`, iconography, quick cutaway b-roll.\nInformative\nFundamentals over Tactics\n3:33-4:05\nEmphasises understanding buyer behaviour beyond tools.\nOverlay \"Master Fundamentals Before Tools\", reflective b-roll, soft `zoom_in`.\nReflective\nStrategy vs Tactics and Core Four\n4:07-7:35\nDifferentiates strategy and tactics; introduces Model, Market, Message, Media.\nProgressive overlays, `flow_chart` animation, category-specific b-roll.\nStructured, didactic\nTactics and Scheduling\n7:36-8:20\nApplies ideas to posting cadence and content types.\nChecklist overlay, subtle `typing_effect`, workflow visuals.\nPractical\nOrganic vs Paid\n8:31-9:20\nContrasts organic content with paid promotion.\nSplit layout overlay, icons, `fade_in_list`, balanced SFX.\nComparative\nDirect Response vs Brand Awareness\n10:20-11:55\nClarifies short-term vs long-term marketing goals.\nDual-column overlay, `zoom_in` warning on \"wrong tool\", case-study b-roll.\nCautionary\nSearch vs Discovery\n12:15-14:05\nHighlights platform intent differences.\nOverlay \"Intent = Key\", platform icons, measured `zoom_in`.\nAnalytical\nProducts vs Services\n14:12-16:05\nExplains tangible vs intangible marketing focus.\nFeature vs Benefit overlay, `ui_pop`, pen demonstration b-roll, service outcome imagery.\nIllustrative\nB2B vs B2C\n16:26-17:11\nDifferentiates business vs consumer audiences.\nComparison overlay with `fade_in_list`, `whoosh_standard`, business/consumer visuals.\nClarifying\nOutro and CTA\n17:03-17:11\nDirects viewers to deeper B2B vs B2C content.\nCTA overlay \"Watch B2B vs B2C Breakdown\", `emphasis_ding`, end-card b-roll.\nEncouraging",
      "Content Consistency: Use canonical terminology (\"digital marketing\", \"traditional marketing\", \"B2B/B2C\", \"feature vs benefit\"). *Rationale:* Vocabulary centralised in [glossary.md](glossary.md) ensures consistent messaging.\nKeep tone authoritative, instructional, and encouraging as reflected in both transcripts. *Rationale:* Matches target audience described in video outlines.\nMaintain chronological order in lists (for example, \"Stage 1 -> Stage 2 -> Stage 3\"). *Rationale:* Prevents cognitive dissonance and supports pedagogy.",
      "Video 1 Narrative Blueprint: This document provides a detailed narrative blueprint for \"Video 1: How I Would Learn Digital Marketing (If I Could Start Over)\". It outlines the video's core elements, including its title, summary, target audience, tone, pacing, and primary themes. This blueprint serves as a guide for AI model training and video plan generation, ensuring that the output aligns with the original video's intent and structure.\n**Title:** *How I Would Learn Digital Marketing (If I Could Start Over)*\n**Summary:** Speaker recounts a 14-year marketing journey, distilling mistakes, learning frameworks, and practice principles into a repeatable roadmap.\n**Target audience:** Early-career marketers who need a structured plan to specialise and grow credibility.\n**Tone and pacing:** Authoritative yet conversational; alternates between reflective storytelling and energetic calls to action.\n**Primary themes:** Focus, structured learning, disciplined practice, career path selection, credibility building.\nSection\nTimestamp\nNarrative focus\nElement opportunities\nEmotional tone\nIntroduction\n0:00-0:35\nEstablishes career credibility and achievements.\n`speaker_intro`, business montage b-roll, magazine overlays, `achievement_highlight` for \"Top 1%\".\nConfident, aspirational\nPart 1: Choose One Area\n0:35-2:02\nShares early missteps and lesson on focus.\nOverlay \"Choose One Area\", b-roll metaphors for distractions, `money_loss` SFX on wasted spend moments.\nCautionary, reflective\nPart 2: Commit to Learning\n2:02-4:24\nIntroduces three-stage learning framework.\nProgressive list overlays, `flow_chart` or `typing_effect` animations, instrument/cooking b-roll metaphors.\nInstructive, structured\nPart 3: Commit to Practicing\n4:24-10:02\nPractical execution guide: cut content, prioritise, agency work, avoid shortcuts, network.\nExpanding checklist overlays, `typing` SFX, agency/workspace b-roll, `zoom_in` on cautionary story beats.\nMotivational, urgent\nCareer Paths\n10:02-11:51\nPresents options: stay generalist, niche down, expand skills.\nComparison table overlay, workplace b-roll varieties, gentle transition effects between options.\nStrategic, optimistic\nConclusion and CTA\n11:51-12:53\nSummarises journey, invites viewers to SEO course.\nClosing overlay \"Start Your SEO Journey\", upbeat b-roll, `success` or `achievement` SFX.\nEncouraging, forward-looking"
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 71,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": true
    },
    "audio_features": {
      "speaking_rate_wps": 2.47
    }
  },
  {
    "index": 25,
    "start": 158.68,
    "end": 165.6,
    "duration": 6.9199999999999875,
    "text": "imprint a forensic immunology focused research organization or fro building",
    "guideline_snippets": [
      "`icon`: **Purpose** - S\u1eed d\u1ee5ng c\u00e1c bi\u1ec3u t\u01b0\u1ee3ng \u0111\u1ed3 h\u1ecda t\u0129nh ho\u1eb7c c\u00f3 chuy\u1ec3n \u0111\u1ed9ng t\u1ed1i thi\u1ec3u \u0111\u1ec3 minh h\u1ecda \u00fd t\u01b0\u1edfng, cung c\u1ea5p th\u00f4ng tin nhanh ch\u00f3ng ho\u1eb7c t\u0103ng c\u01b0\u1eddng nh\u1eadn di\u1ec7n th\u01b0\u01a1ng hi\u1ec7u.\n**Layer** - `overlay` (l\u1edbp ph\u1ee7).\n**Key fields** - `content` (n\u1ed9i dung bi\u1ec3u t\u01b0\u1ee3ng, th\u01b0\u1eddng l\u00e0 t\u00ean file ho\u1eb7c ID), `context` (ng\u1eef c\u1ea3nh s\u1eed d\u1ee5ng).",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Practice Principles: **Pattern**: Iconography with brief text overlays for key principles.\n**Elements**: `icon` (overlay layer) with relevant `content` (e.g., lightbulb for \"innovation\"), accompanied by `text_overlay` with `clean_minimal` style.\n**Rationale**: Provides quick visual cues for abstract concepts, enhancing comprehension and retention."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 75,
      "sentence_count": 0,
      "word_count": 10,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.45
    }
  },
  {
    "index": 26,
    "start": 165.6,
    "end": 170.48,
    "duration": 4.8799999999999955,
    "text": "machine learning and experimental tools to identify the hidden causes of and",
    "guideline_snippets": [
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores.",
      "4. Model Strategy: Treat timestamp and duration predictions as regression; element presence and type as multi-label or multi-class classification.\nConsider hierarchical modelling: first detect whether an element occurs, then specialise by element family.\nExplore sequence-to-sequence or encoder-decoder approaches for generating ordered element lists.\nReserve capacity for generative text (for example, overlay copy) via template libraries or conditional generation models.",
      "Integration Touchpoints: **Feature Engineering** - include catalog tags as additional inputs when predicting `description` or `sound`.\n**Inference** - post-process model outputs by selecting the closest matching `id` using cosine similarity between description embeddings and catalog tags.\n**Evaluation** - add assertions in `quality_criteria.md` to confirm selected assets exist and comply with `motion_rules.json`.\nRefer back to `knowledge-base/data_sources.md` for provenance and to `planning_guidelines.md` for contextual placement rules."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.46
    }
  },
  {
    "index": 27,
    "start": 170.48,
    "end": 176.76,
    "duration": 6.280000000000001,
    "text": "cures for chronic disease currently we are generously supported by Eric and",
    "guideline_snippets": [
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "Recurring Cues: `highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time.",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 75,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.91
    }
  },
  {
    "index": 28,
    "start": 176.76,
    "end": 182.68,
    "duration": 5.920000000000016,
    "text": "Wendy Schmidt convergent research and the city of New York we're also yeah",
    "guideline_snippets": [
      "Recurring Cues: Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery.",
      "Video 1 Narrative Blueprint: This document provides a detailed narrative blueprint for \"Video 1: How I Would Learn Digital Marketing (If I Could Start Over)\". It outlines the video's core elements, including its title, summary, target audience, tone, pacing, and primary themes. This blueprint serves as a guide for AI model training and video plan generation, ensuring that the output aligns with the original video's intent and structure.\n**Title:** *How I Would Learn Digital Marketing (If I Could Start Over)*\n**Summary:** Speaker recounts a 14-year marketing journey, distilling mistakes, learning frameworks, and practice principles into a repeatable roadmap.\n**Target audience:** Early-career marketers who need a structured plan to specialise and grow credibility.\n**Tone and pacing:** Authoritative yet conversational; alternates between reflective storytelling and energetic calls to action.\n**Primary themes:** Focus, structured learning, disciplined practice, career path selection, credibility building.\nSection\nTimestamp\nNarrative focus\nElement opportunities\nEmotional tone\nIntroduction\n0:00-0:35\nEstablishes career credibility and achievements.\n`speaker_intro`, business montage b-roll, magazine overlays, `achievement_highlight` for \"Top 1%\".\nConfident, aspirational\nPart 1: Choose One Area\n0:35-2:02\nShares early missteps and lesson on focus.\nOverlay \"Choose One Area\", b-roll metaphors for distractions, `money_loss` SFX on wasted spend moments.\nCautionary, reflective\nPart 2: Commit to Learning\n2:02-4:24\nIntroduces three-stage learning framework.\nProgressive list overlays, `flow_chart` or `typing_effect` animations, instrument/cooking b-roll metaphors.\nInstructive, structured\nPart 3: Commit to Practicing\n4:24-10:02\nPractical execution guide: cut content, prioritise, agency work, avoid shortcuts, network.\nExpanding checklist overlays, `typing` SFX, agency/workspace b-roll, `zoom_in` on cautionary story beats.\nMotivational, urgent\nCareer Paths\n10:02-11:51\nPresents options: stay generalist, niche down, expand skills.\nComparison table overlay, workplace b-roll varieties, gentle transition effects between options.\nStrategic, optimistic\nConclusion and CTA\n11:51-12:53\nSummarises journey, invites viewers to SEO course.\nClosing overlay \"Start Your SEO Journey\", upbeat b-roll, `success` or `achievement` SFX.\nEncouraging, forward-looking",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 74,
      "sentence_count": 0,
      "word_count": 13,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.2
    }
  },
  {
    "index": 29,
    "start": 182.68,
    "end": 189.92,
    "duration": 7.239999999999981,
    "text": "New York right and everything we're also going to apply these tools to",
    "guideline_snippets": [
      "Usage Guidance: Review `data_sources.md` to understand raw inputs and supporting catalogs.\nAlign feature engineering and targets using `training_pipeline.md`, `element_definitions.md`, and `element_schema.json`.\nDuring plan generation, enforce `planning_guidelines.md` and validate against `quality_criteria.md`.\nLeverage `asset_catalogs.md` alongside the JSON catalogs to ensure selected assets exist and honour motion rules.\nConsult `videos/` and `examples/` for grounded samples (positive and negative) before crafting prompts, labels, or rule-based validators.\nLog any documentation changes in `CHANGELOG.md` so training runs can reference the correct knowledge base version.",
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores.",
      "Integration Touchpoints: **Feature Engineering** - include catalog tags as additional inputs when predicting `description` or `sound`.\n**Inference** - post-process model outputs by selecting the closest matching `id` using cosine similarity between description embeddings and catalog tags.\n**Evaluation** - add assertions in `quality_criteria.md` to confirm selected assets exist and comply with `motion_rules.json`.\nRefer back to `knowledge-base/data_sources.md` for provenance and to `planning_guidelines.md` for contextual placement rules."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 70,
      "sentence_count": 0,
      "word_count": 13,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.8
    }
  },
  {
    "index": 30,
    "start": 189.92,
    "end": 193.96,
    "duration": 4.0400000000000205,
    "text": "intractable chronic diseases particularly neurological and psychiatric",
    "guideline_snippets": [
      "`sound_effect`: **Purpose** - S\u1eed d\u1ee5ng c\u00e1c t\u00edn hi\u1ec7u \u00e2m thanh ng\u1eafn \u0111\u1ec3 nh\u1ea5n m\u1ea1nh c\u00e1c kho\u1ea3nh kh\u1eafc quan tr\u1ecdng, t\u1ea1o c\u1ea3m x\u00fac ho\u1eb7c t\u0103ng c\u01b0\u1eddng tr\u1ea3i nghi\u1ec7m ng\u01b0\u1eddi xem.\n**Layer** - `audio` (l\u1edbp \u00e2m thanh).\n**Key field** - `sound` (tham chi\u1ebfu \u0111\u1ebfn ID \u00e2m thanh trong `sfx_catalog.json`).\n**Common sounds** - `transition_rewind` (chuy\u1ec3n c\u1ea3nh tua l\u1ea1i), `whoosh_standard` (ti\u1ebfng v\u00fat ti\u00eau chu\u1ea9n), `ui_pop` (ti\u1ebfng pop giao di\u1ec7n ng\u01b0\u1eddi d\u00f9ng), `money` (ti\u1ec1n), `success` (th\u00e0nh c\u00f4ng), `fire` (l\u1eeda), `achievement` (th\u00e0nh t\u1ef1u), `crash` (va ch\u1ea1m), `money_loss` (m\u1ea5t ti\u1ec1n), `typing` (g\u00f5 ph\u00edm), `confusion` (b\u1ed1i r\u1ed1i), `expansion` (m\u1edf r\u1ed9ng), `emphasis_ding` (ti\u1ebfng ding nh\u1ea5n m\u1ea1nh), `heartbeat_soft` (ti\u1ebfng tim \u0111\u1eadp nh\u1eb9).\n**Defaults** - Ph\u00e1t m\u1ed9t l\u1ea7n v\u1edbi th\u1eddi l\u01b0\u1ee3ng \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi t\u00e0i s\u1ea3n \u00e2m thanh g\u1ed1c.",
      "Purpose: The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 70,
      "sentence_count": 0,
      "word_count": 7,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.73
    }
  },
  {
    "index": 31,
    "start": 193.96,
    "end": 200.64,
    "duration": 6.679999999999978,
    "text": "disorders so why neuropsych right emerging evidence including some of my",
    "guideline_snippets": [
      "Usage: **Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 72,
      "sentence_count": 0,
      "word_count": 11,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.65
    }
  },
  {
    "index": 32,
    "start": 200.64,
    "end": 206.16,
    "duration": 5.52000000000001,
    "text": "own work suggested a lot of what we are calling psychiatric disorders are",
    "guideline_snippets": [
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Sound Effects: Pair new terms or section changes with subtle SFX (`ui_pop`, `whoosh_standard`). *Rationale:* Audio cues boost recall and correspond to assets in `sfx_catalog.json`.\nReserve `money`, `success`, or `achievement` sounds for monetary claims or milestones. *Rationale:* Prevents semantic drift and keeps the acoustic palette purposeful.\nUse `typing` sounds only when animations or narration mention writing or typing. *Rationale:* Maintains cohesive audiovisual storytelling.",
      "2025-10-21: Added `element_schema.json` to formalise element structure, allowed values, and validation rules.\nExpanded `examples/` with qualitative (`patterns.md`) and structured (`patterns.json`) cases, including edge and negative scenarios.\nIntroduced `asset_catalogs.md` and documented catalog usage in `data_sources.md`.\nRefined `planning_guidelines.md` with cross-references, rationales, and motion spacing rules.\nUpgraded video outlines to narrative blueprints with summaries, audiences, and emotional tone guidance.\nExpanded `glossary.md` to cover modelling terminology (Sentence-BERT, MAE, F1, etc.).\nUpdated `README.md` with new directory map and versioning instructions."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 73,
      "sentence_count": 0,
      "word_count": 13,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.36
    }
  },
  {
    "index": 33,
    "start": 206.2,
    "end": 212.0,
    "duration": 5.800000000000011,
    "text": "actually immune diseases so for example the immune system stores a memory of",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Purpose: The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`.",
      "Usage: **Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 13,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.24
    }
  },
  {
    "index": 34,
    "start": 212.0,
    "end": 218.4,
    "duration": 6.400000000000006,
    "text": "psychological stress and is involved in stress resilience and a lot of cases of",
    "guideline_snippets": [
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Usage: **Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 79,
      "sentence_count": 0,
      "word_count": 14,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.19
    }
  },
  {
    "index": 35,
    "start": 218.4,
    "end": 222.56,
    "duration": 4.159999999999997,
    "text": "schizophrenia are actually turning out to be driven by underlying auto immune",
    "guideline_snippets": [
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores.",
      "9. Risk Controls: Mitigate noisy timestamps by smoothing predictions and enforcing minimum separation thresholds defined in `motion_rules.json`.\nPrevent style drift by constraining `style` predictions to allowed set per brand guide.\nDocument assumptions about transcript accuracy; include fallbacks when speech deviates from script."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 77,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.88
    }
  },
  {
    "index": 36,
    "start": 222.56,
    "end": 230.08,
    "duration": 7.52000000000001,
    "text": "disease and the shingles vaccine might prevent dementia and there's also",
    "guideline_snippets": [
      "Sound Effects: Pair new terms or section changes with subtle SFX (`ui_pop`, `whoosh_standard`). *Rationale:* Audio cues boost recall and correspond to assets in `sfx_catalog.json`.\nReserve `money`, `success`, or `achievement` sounds for monetary claims or milestones. *Rationale:* Prevents semantic drift and keeps the acoustic palette purposeful.\nUse `typing` sounds only when animations or narration mention writing or typing. *Rationale:* Maintains cohesive audiovisual storytelling.",
      "9. Risk Controls: Mitigate noisy timestamps by smoothing predictions and enforcing minimum separation thresholds defined in `motion_rules.json`.\nPrevent style drift by constraining `style` predictions to allowed set per brand guide.\nDocument assumptions about transcript accuracy; include fallbacks when speech deviates from script.",
      "Recurring Cues: `highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 72,
      "sentence_count": 0,
      "word_count": 11,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.46
    }
  },
  {
    "index": 37,
    "start": 230.08,
    "end": 234.08,
    "duration": 4.0,
    "text": "everything that we saw during the pandemic right COVID causing de novo",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 70,
      "sentence_count": 0,
      "word_count": 12,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 3.0
    }
  },
  {
    "index": 38,
    "start": 234.16,
    "end": 240.92,
    "duration": 6.759999999999991,
    "text": "psychiatric disorders long COVID so really we are in the middle of an",
    "guideline_snippets": [
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
      "2. Preprocess & Align: Merge transcript text with timeline entries by timestamp, producing windows (5-10 seconds) that give sufficient context.\nNormalize timestamps to seconds for easier maths and modelling.\nSegment transcripts into sentences or clauses; tokenise and build embeddings (Sentence-BERT or equivalent).\nEncode video elements: one-hot for categorical fields, embeddings for text-heavy attributes (`description`, `content`); ensure categorical vocab matches [element_schema.json](element_schema.json)."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 69,
      "sentence_count": 0,
      "word_count": 13,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.92
    }
  },
  {
    "index": 39,
    "start": 240.92,
    "end": 246.36,
    "duration": 5.440000000000026,
    "text": "immunotherapy revolution for cancer right some cancers that had 90%",
    "guideline_snippets": [
      "Content Accuracy: On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract.",
      "Recurring Cues: Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery.",
      "Coverage: Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 67,
      "sentence_count": 0,
      "word_count": 10,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.84
    }
  },
  {
    "index": 40,
    "start": 246.36,
    "end": 253.36,
    "duration": 7.0,
    "text": "mortality rates 50 years ago now have 90% cure rates what if we could extend",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Recurring Cues: `highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time.",
      "9. Risk Controls: Mitigate noisy timestamps by smoothing predictions and enforcing minimum separation thresholds defined in `motion_rules.json`.\nPrevent style drift by constraining `style` predictions to allowed set per brand guide.\nDocument assumptions about transcript accuracy; include fallbacks when speech deviates from script."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.14
    }
  },
  {
    "index": 41,
    "start": 253.36,
    "end": 261.8,
    "duration": 8.439999999999998,
    "text": "that revolution to auto immunity diabetes dementia depression maybe in 15",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "Review Workflow: Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 73,
      "sentence_count": 0,
      "word_count": 11,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.3
    }
  },
  {
    "index": 42,
    "start": 261.84,
    "end": 267.68,
    "duration": 5.840000000000032,
    "text": "years if we can learn what the immune system already knows we could take the",
    "guideline_snippets": [
      "Changelog: All notable changes to the AI planning knowledge base will be documented in this file.",
      "1. Audit Existing Data & Targets: Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps.",
      "2. Preprocess & Align: Merge transcript text with timeline entries by timestamp, producing windows (5-10 seconds) that give sufficient context.\nNormalize timestamps to seconds for easier maths and modelling.\nSegment transcripts into sentences or clauses; tokenise and build embeddings (Sentence-BERT or equivalent).\nEncode video elements: one-hot for categorical fields, embeddings for text-heavy attributes (`description`, `content`); ensure categorical vocab matches [element_schema.json](element_schema.json)."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 76,
      "sentence_count": 0,
      "word_count": 15,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 2.57
    }
  },
  {
    "index": 43,
    "start": 267.68,
    "end": 273.28,
    "duration": 5.599999999999966,
    "text": "chronic out of chronic disease thank you",
    "guideline_snippets": [
      "Recurring Cues: `highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time.",
      "8. Maintenance Cadence: Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
      "6. Evaluation: Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors."
    ],
    "plan_elements": [],
    "encoded_features": {
      "num_elements": 0,
      "avg_element_duration": 0.0
    },
    "text_features": {
      "text_length": 40,
      "sentence_count": 0,
      "word_count": 7,
      "relative_position": 0.0,
      "has_keyword_t\u01b0\u01a1ng_lai": false,
      "has_keyword_c\u00f4ng_ngh\u1ec7": false,
      "has_keyword_ai": false
    },
    "audio_features": {
      "speaking_rate_wps": 1.25
    }
  }
]